<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>iot proj</title>
  </head>
  <body onload="init()">
    <div>Teachable Machine Image Model</div>
    <div id="webcam-container"></div>
    <div id="label-container"></div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>
    <script type="text/javascript">
      // More API functions here:
      // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

      // the link to your model provided by Teachable Machine export panel

      let model,
        webcam,
        labelContainer,
        maxPredictions,
        API_req_endpoint = "https://reqres.in/api/users?page=";

      // more documentation available at
      // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands

      // the link to your model provided by Teachable Machine export panel
      // const URL = "./sound_model/";
      async function createModel() {
        const URL = "http://127.0.0.1:5500/sound_model/";
        const checkpointURL = URL + "model.json"; // model topology
        const metadataURL = URL + "metadata.json"; // model metadata

        const recognizer = speechCommands.create(
          "BROWSER_FFT", // fourier transform type, not useful to change
          undefined, // speech commands vocabulary feature, not useful for your models
          checkpointURL,
          metadataURL
        );

        // check that model and metadata are loaded via HTTPS requests.
        await recognizer.ensureModelLoaded();

        return recognizer;
      }

      // Load the image and sound model and setup the webcam and microphone
      async function init() {
        /*Sound model init*/
        const recognizer = await createModel();
        const classLabels = recognizer.wordLabels(); // get class labels
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < classLabels.length; i++) {
          labelContainer.appendChild(document.createElement("div"));
        }

        // listen() takes two arguments:
        // 1. A callback function that is invoked anytime a word is recognized.
        // 2. A configuration object with adjustable fields

        let last_predval = 0,
          last_predclass = "";
        recognizer.listen(
          (result) => {
            const scores = result.scores; // probability of prediction for each class
            // render the probability scores per class
            for (let i = 0; i < classLabels.length; i++) {
              const predval = result.scores[i].toFixed(2);
              const predclass = classLabels[i];
              if (predval > 0.7 && last_predclass !== predclass) {
                last_predclass = predclass;
                last_predval = predval;
                const soundPrediction =
                  classLabels[i] + ": " + result.scores[i].toFixed(2);
                labelContainer.childNodes[0].innerHTML =
                  "Sound Classification -> " + soundPrediction;
                console.log("inside sound fetch");

                var xhttp = new XMLHttpRequest();
                xhttp.open("GET", API_req_endpoint + predclass, true);
                xhttp.send();
                // console.log(xhttp.responseText);
              }
            }
          },
          {
            includeSpectrogram: true, // in case listen should return result.spectrogram
            probabilityThreshold: 0.75,
            invokeCallbackOnNoiseAndUnknown: true,
            overlapFactor: 0.5, // probably want between 0.5 and 0.75. More info in README
          }
        );

        // Stop the recognition in 5 seconds.
        // setTimeout(() => recognizer.stopListening(), 5000);
        /////////////////////////////////////////////////////////////
        /*Image model init*/
        const URL = "./my_model/";
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
      }

      let last_imgpredval = 0,
        last_imgpredclass = 0;
      async function loop() {
        webcam.update(); // update the webcam frame
        predict();
        window.requestAnimationFrame(loop);
      }

      // run the webcam image through the image model
      async function predict() {
        // predict can take in an image, video or canvas html element

        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
          const predval = prediction[i].probability.toFixed(2);
          const predclass = prediction[i].className;

          const classPrediction =
            prediction[i].className +
            ": " +
            prediction[i].probability.toFixed(2);

          if (predval > 0.7 && predclass != last_imgpredclass) {
            console.log(
              "inside image fetch",
              predval,
              last_imgpredval,
              predclass,
              last_imgpredclass
            );

            last_imgpredclass = predclass;
            last_imgpredval = predval;
            labelContainer.childNodes[1].innerHTML =
              "Image Classification -> " + classPrediction;

            var xhttp = new XMLHttpRequest();
            xhttp.open("GET", API_req_endpoint + predclass, true);
            xhttp.send();
            // console.log(xhttp.responseText);
          }
          // labelContainer.childNodes[i].innerHTML = classPrediction;
        }
      }
    </script>
  </body>
</html>
